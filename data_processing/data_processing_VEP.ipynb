{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "import os\n",
    "import xlrd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mutations_per_position(df):\n",
    "    # Print number of NA\n",
    "    print(f'Number of NA: {df[\"variant\"].isna().sum()}')\n",
    "    # Print number of WT\n",
    "    if \"WT\" in df[\"variant\"].unique():\n",
    "        print(f'Number of WT: {df[\"variant\"].value_counts()[\"WT\"]}')\n",
    "    else:\n",
    "        print('WT not found in mutation column')\n",
    "    # Filter out rows with missing or \"WT\" mutations\n",
    "    df_filtered = df.dropna(subset=[\"variant\"]).query('variant != \"WT\"')\n",
    "\n",
    "    # Initialize an empty dictionary to store the number of mutations per position\n",
    "    mutations_per_position = {}\n",
    "    \n",
    "    # Print the size of the dataset\n",
    "    print(f'Number of variants: {len(df_filtered)}')\n",
    "\n",
    "    # Print the number of fitness_binary = 1 values\n",
    "    print(f'Number of fitness_binary = 1: {len(df_filtered.query(\"fitness_binary == 1\"))}')\n",
    "\n",
    "    # Iterate over the rows of the DataFrame and increment the count of mutations at each position\n",
    "    for mutation_str in df_filtered[\"variant\"]:\n",
    "        # Remove the initial and final characters from the mutation string\n",
    "        pos = int(mutation_str[1:-1])\n",
    "\n",
    "        # Increment the count of mutations at this position in the dictionary\n",
    "        if pos in mutations_per_position:\n",
    "            mutations_per_position[pos] += 1\n",
    "        else:\n",
    "            mutations_per_position[pos] = 1\n",
    "\n",
    "    # Plot a histogram of the number of mutations per position\n",
    "    plt.bar(mutations_per_position.keys(), mutations_per_position.values())\n",
    "    plt.xlabel('Number of mutations')\n",
    "    plt.ylabel('Number of positions')\n",
    "    plt.title('Mutations per position')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_of_readout(df, column_name, cutoff=None):\n",
    "    # Plot histogram of readout values for all mutants\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(df[column_name].values, bins=100)\n",
    "    ax.set_xlabel(column_name)\n",
    "    ax.set_ylabel('Number of mutants')\n",
    "    ax.set_title(f'{column_name} distribution across mutants')\n",
    "    \n",
    "    # Add vertical line to indicate WT value\n",
    "    # if there is a WT value, add a vertical line\n",
    "    if \"WT\" in df[\"variant\"].unique():\n",
    "        wt_val = df.loc[df[\"variant\"] == 'WT', column_name].values[0]\n",
    "        ax.axvline(wt_val, color='red', linestyle='--', label='WT')\n",
    "    # Add vertical line to indicate cutoff value\n",
    "    if cutoff:\n",
    "        ax.axvline(cutoff, color='black', linestyle='--', label='cutoff')\n",
    "    ax.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name=None, cutoff_rule='greater_than', AA_shift=None):\n",
    "\n",
    "    # Check file extension to determine the appropriate reading method\n",
    "    if file_path.endswith('.xlsx'):\n",
    "        if isinstance(sheet_name, str):\n",
    "            # Read the Excel file with the specified sheet name\n",
    "            dataframe = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        else:\n",
    "            # Read the Excel file without specifying a sheet name\n",
    "            dataframe = pd.read_excel(file_path)\n",
    "    elif file_path.endswith('.csv'):\n",
    "        # Read the CSV file\n",
    "        dataframe = pd.read_csv(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide an Excel (.xlsx) or CSV (.csv) file.\")\n",
    "\n",
    "    # Filter out rows with missing values in the fitness column\n",
    "    filtered_df = dataframe.dropna(subset=[fitness_column])\n",
    "\n",
    "    # Read the WT sequence based on FASTA file\n",
    "    fasta_file = f'dataframes_VEP/{dataset_name}_WT.fasta'\n",
    "\n",
    "    sequences = SeqIO.parse(fasta_file, 'fasta')\n",
    "\n",
    "    for record in sequences:\n",
    "        wt_sequence = str(record.seq)\n",
    "        break\n",
    "    \n",
    "    # print(f'WT sequence: {wt_sequence}')\n",
    "\n",
    "    # Write the filtered dataframe to a FASTA file\n",
    "    output_file = f'output/{dataset_name}.fasta'\n",
    "    with open(output_file, 'w') as f:\n",
    "        for variant in filtered_df['variant']:\n",
    "            # extract the integer position from the variant string\n",
    "            # if AA_shift is None, then the position is the integer in the variant string\n",
    "            if 'WT' in variant:\n",
    "                f.write(f'>{variant}\\n{wt_sequence}\\n')             \n",
    "            else:\n",
    "                if AA_shift is None:\n",
    "                    position = int(variant[1:-1]) - 1\n",
    "                else:\n",
    "                    position = int(variant[1:-1]) - AA_shift\n",
    "                # extract the WT amino acid from the variant string\n",
    "                wt_aa = variant[0]\n",
    "                # extract the mutated amino acid from the variant string\n",
    "                mutated_aa = variant[-1]\n",
    "\n",
    "                # print(f'Position: {position}, WT AA: {wt_aa}, Mutated AA: {mutated_aa}')\n",
    "\n",
    "                if wt_sequence[position] == wt_aa:\n",
    "                    sequence = wt_sequence[:position] + mutated_aa + wt_sequence[position+1:]\n",
    "                    f.write(f'>{variant}\\n{sequence}\\n')\n",
    "                else:\n",
    "                    print(f'Error: WT amino acid at position {position} is not {wt_aa}')\n",
    "\n",
    "    # Make a fitness column called 'fitness' from fitness_column\n",
    "    filtered_df['fitness'] = filtered_df[fitness_column]\n",
    "\n",
    "    # Make a min-max scaled column called 'fitness_scaled' from fitness_column\n",
    "    filtered_df['fitness_scaled'] = (filtered_df[fitness_column] - filtered_df[fitness_column].min()) / (filtered_df[fitness_column].max() - filtered_df[fitness_column].min())\n",
    "\n",
    "    # Make a binary column called 'fitness_binary' from fitness_column\n",
    "    if cutoff_rule == 'greater_than':\n",
    "        filtered_df.loc[:, 'fitness_binary'] = np.where(filtered_df[fitness_column] > cutoff_value, 1, 0)\n",
    "    elif cutoff_rule == 'less_than':\n",
    "        filtered_df.loc[:, 'fitness_binary'] = np.where(filtered_df[fitness_column] < cutoff_value, 1, 0)\n",
    "\n",
    "    # Save the filtered dataframe to a CSV file dataset_name_labels.csv in the /output/ folder\n",
    "    filtered_df.to_csv(f'output/{dataset_name}_labels.csv', index=False)\n",
    "\n",
    "    # Plot histogram of readout values for all mutants\n",
    "    plot_histogram_of_readout(filtered_df, 'fitness_scaled')\n",
    "    plot_histogram_of_readout(filtered_df, 'fitness', cutoff=cutoff_value)\n",
    "\n",
    "    # plot mutations per position\n",
    "    plot_mutations_per_position(filtered_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brenan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'brenan'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS_SCH'  # Provide the fitness column name\n",
    "sheet_name = 'MAPK1'  # Provide the sheet name\n",
    "cutoff_value = 2.5  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giacomelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'giacomelli'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS_null_etoposide'  # Provide the fitness column name\n",
    "sheet_name = 'P53'  # Provide the sheet name\n",
    "cutoff_value = 1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'jones'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS_0.625'  # Provide the fitness column name\n",
    "sheet_name = 'ADRB2'  # Provide the sheet name\n",
    "cutoff_value = 2.8  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'kelsic'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS_rich'  # Provide the fitness column name\n",
    "sheet_name = 'infA'  # Provide the sheet name\n",
    "cutoff_value = 0.98  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stiffler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'stiffler'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS_amp_2500_(b)'  # Provide the fitness column name\n",
    "sheet_name = 'bla'  # Provide the sheet name\n",
    "cutoff_value = 0.01  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haddox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'haddox'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS'  # Provide the fitness column name\n",
    "sheet_name = 'env'  # Provide the sheet name\n",
    "cutoff_value = 0.1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'doud'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS'  # Provide the fitness column name\n",
    "sheet_name = 'HA-H1N1'  # Provide the sheet name\n",
    "cutoff_value = 0.1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Source.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'lee'  # Provide the dataset sheet name\n",
    "fitness_column = 'DMS'  # Provide the fitness column name\n",
    "sheet_name = 'HA-H3N2'  # Provide the sheet name\n",
    "cutoff_value = 0.1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, sheet_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/abf8761_markin_data-s1.csv'  # Provide the path to the Excel file\n",
    "dataset_name = 'markin'  # Provide the dataset sheet name\n",
    "fitness_column = 'kcatOverKM_cMUP_M-1s-1'  # Provide the fitness column name\n",
    "cutoff_value = 0.01  # Provide the cutoff value\n",
    "cutoff_rule = 'less_than'  # Provide the cutoff rule\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value, cutoff_rule=cutoff_rule, AA_shift=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in markin data and filter for variants with p-value < 0.01\n",
    "markin = pd.read_csv('dataframes_VEP/abf8761_markin_data-s1.csv')\n",
    "# get kcatOverKM_cMUP_M-1s-1 variable for WT\n",
    "markin_WT_fitness = markin[markin['variant'] == 'WT']['kcatOverKM_cMUP_M-1s-1'].values[0]\n",
    "# read in markin data and filter for variants with p-value < 0.01\n",
    "markin = pd.read_csv('output/markin_labels.csv')\n",
    "# fix the fitness_binary column\n",
    "markin['fitness_binary'] = np.where((markin['kcatOverKM_cMUP_p-value'] < 0.01) & (markin['kcatOverKM_cMUP_M-1s-1'] > markin_WT_fitness), 1, 0)\n",
    "# save markin dataframe\n",
    "markin.to_csv('output/markin_labels.csv')\n",
    "# count the number of fitness_binary values\n",
    "markin['fitness_binary'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas12f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in DMS_AsCas12f.xlsx\n",
    "DMS_AsCas12f = pd.read_excel('dataframes_VEP/DMS_AsCas12f.xlsx')\n",
    "\n",
    "# extract the as the character in variant column, stripping the integers in the column\n",
    "DMS_AsCas12f['substition'] = DMS_AsCas12f['variant'].str[0]\n",
    "# extract the position as the integer in variant column, stripping the characters in the column\n",
    "DMS_AsCas12f['position'] = DMS_AsCas12f['variant'].str[1:].astype(int)\n",
    "# filter for rows where mean = 1\n",
    "DMS_AsCas12f_WT = DMS_AsCas12f[DMS_AsCas12f['mean'] == 1]\n",
    "DMS_AsCas12f_WT = DMS_AsCas12f_WT.rename(columns={'substition': 'WT'})\n",
    "DMS_AsCas12f_WT = DMS_AsCas12f_WT[['WT', 'position']]\n",
    "\n",
    "# write a fasta file that is the concatenation of the WT column\n",
    "with open('dataframes_VEP/cas12f_WT.fasta', 'w') as f:\n",
    "    f.write(f'>AsCas12f\\n{\"\".join(DMS_AsCas12f_WT[\"WT\"].values)}\\n')\n",
    "\n",
    "# change name of column position to WT\n",
    "DMS_AsCas12f = DMS_AsCas12f[DMS_AsCas12f['mean'] != 1]\n",
    "DMS_AsCas12f = DMS_AsCas12f.rename(columns={'variant': 'variant_raw'})\n",
    "\n",
    "# left join to DMS_AsCas12f with only position and WT column\n",
    "DMS_AsCas12f = DMS_AsCas12f.merge(DMS_AsCas12f_WT[['position', 'WT']], how='left', on='position')\n",
    "DMS_AsCas12f\n",
    "\n",
    "# make a column variant that is the concatenation of WT, position, and substition\n",
    "DMS_AsCas12f['variant'] = DMS_AsCas12f['WT'] + DMS_AsCas12f['position'].astype(str) + DMS_AsCas12f['substition']\n",
    "DMS_AsCas12f\n",
    "\n",
    "# remove column No\n",
    "DMS_AsCas12f = DMS_AsCas12f.drop(columns=['No'])\n",
    "\n",
    "# filter out rows where substition is *\n",
    "DMS_AsCas12f = DMS_AsCas12f[DMS_AsCas12f['substition'] != '*']\n",
    "# filter out rows where mean is NA\n",
    "DMS_AsCas12f = DMS_AsCas12f[~DMS_AsCas12f['mean'].isna()]\n",
    "# change mean to fitness\n",
    "DMS_AsCas12f = DMS_AsCas12f.rename(columns={'mean': 'fitness'})\n",
    "# add a row for WT where column variant = WT and mean = 1\n",
    "WT_row = {\n",
    "    'variant_raw': 'WT',\n",
    "    'rep1': 1.0,\n",
    "    'rep2': 1.0,\n",
    "    'WT': 'WT',\n",
    "    'position': np.nan,  # Set 'position' to blank (NaN)\n",
    "    'substition': np.nan,  # Set 'substition' to blank (NaN)\n",
    "    'fitness': 1.0,\n",
    "    'variant': 'WT'\n",
    "}\n",
    "DMS_AsCas12f = DMS_AsCas12f.append(WT_row, ignore_index=True)\n",
    "\n",
    "# write an excel file out of DMS_AsCas12f\n",
    "DMS_AsCas12f.to_excel('dataframes_VEP/DMS_AsCas12f_clean.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/DMS_AsCas12f_clean.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'cas12f'  # Provide the dataset sheet name\n",
    "fitness_column = 'fitness'  # Provide the fitness column name\n",
    "cutoff_value = 1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zika Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in jvi.01291-19-sd003.xlsx, sheet mutational effects\n",
    "jvi = pd.read_excel('dataframes_VEP/jvi.01291-19-sd003.xlsx', sheet_name='mutational effects')\n",
    "\n",
    "# change column mutation to variant and effect to fitness\n",
    "jvi = jvi.rename(columns={'mutation': 'variant', 'effect': 'fitness'})\n",
    "\n",
    "# filter for wildtype = mutant\n",
    "jvi_WT = jvi[jvi['wildtype'] == jvi['mutant']]\n",
    "\n",
    "# write a fasta file that is the concatenation of the WT column\n",
    "with open('dataframes_VEP/zikv_E_WT.fasta', 'w') as f:\n",
    "    f.write(f'>Zikv_E\\n{\"\".join(jvi_WT[\"wildtype\"].values)}\\n')\n",
    "\n",
    "WT_row = {\n",
    "    'variant': 'WT',\n",
    "    'site': np.nan,  # Set 'position' to blank (NaN)\n",
    "    'wildtype': np.nan,  # Set 'substition' to blank (NaN)\n",
    "    'mutant': np.nan,\n",
    "    'fitness': 1.0,\n",
    "    'log2effect': 0.0\n",
    "}\n",
    "\n",
    "jvi = jvi[jvi['wildtype'] != jvi['mutant']]\n",
    "jvi = jvi.append(WT_row, ignore_index=True)\n",
    "\n",
    "# write excel file out of jvi\n",
    "jvi.to_excel('dataframes_VEP/Zikv_E.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/Zikv_E.xlsx'  # Provide the path to the Excel file\n",
    "dataset_name = 'zikv_E'  # Provide the dataset sheet name\n",
    "fitness_column = 'fitness'  # Provide the fitness column name\n",
    "cutoff_value = 1  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sars Cov2 S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all_samples_raw_data--sarscov2.csv\n",
    "sarscov2 = pd.read_csv('dataframes_VEP/all_samples_raw_data--sarscov2.csv')\n",
    "\n",
    "# make a column variant that is the concatenation of WT, position, and substition\n",
    "sarscov2['variant'] = sarscov2['wildtype'] + sarscov2['site'].astype(str) + sarscov2['mutation']\n",
    "\n",
    "# drop site_total_escape and site_max_escape\n",
    "sarscov2 = sarscov2.drop(columns=['site_total_escape', 'site_max_escape','condition'])\n",
    "\n",
    "# rename mut_escape to fitness\n",
    "sarscov2 = sarscov2.rename(columns={'mut_escape': 'fitness'})\n",
    "\n",
    "# Assuming your DataFrame is named df\n",
    "# Group by 'variant' and calculate the mean fitness for each group\n",
    "sarscov2_averaged = sarscov2.groupby(['variant', 'site', 'wildtype', 'mutation']).agg({\n",
    "    'fitness': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "sarscov2_averaged = sarscov2_averaged.sort_values(by=['site'])\n",
    "sarscov2_averaged\n",
    "\n",
    "# write a csv file out of sarscov2_averaged\n",
    "sarscov2_averaged.to_csv('dataframes_VEP/sarscov2_averaged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'dataframes_VEP/sarscov2_averaged.csv'  # Provide the path to the Excel file\n",
    "dataset_name = 'cov2_S'  # Provide the dataset sheet name\n",
    "fitness_column = 'fitness'  # Provide the fitness column name\n",
    "cutoff_value = 0.05  # Provide the cutoff value\n",
    "\n",
    "process_dataset(file_path, dataset_name, fitness_column, cutoff_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of settings\n",
    "settings = [\n",
    "    [ 'dms_adrb2', 'DMS_0.625', 2.8, 2,  'jones'],\n",
    "    [ 'dms_bla', 'DMS_amp_2500_(b)', 0.01, 2, 'stiffler' ],\n",
    "    [ 'dms_env', 'DMS', 0.1, 2, 'haddox' ],\n",
    "    [ 'dms_ha_h1', 'DMS', 0.1, 2, 'doud' ],\n",
    "    [ 'dms_ha_h3', 'DMS', 0.1, 2, 'lee' ],\n",
    "    [ 'dms_infa', 'DMS_min', 0.98, 1, 'kelsic' ],\n",
    "    [ 'dms_mapk1', 'DMS_SCH', 2.5, 1, 'brenan' ],\n",
    "    [ 'dms_p53', 'DMS_null_etoposide', 1, 2, 'giacomelli' ],\n",
    "    [ 'dms_pafa', 'DMS_kcat_km', 2300000, 1, 'markin' ],\n",
    "]\n",
    "\n",
    "for namespace, dms_name, cutoff, k_cutoff, dataset_name in settings:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(f'dms/{namespace}_esm.csv', delimiter=',')\n",
    "    \n",
    "    # Filter based on ESM_vote >= k_cutoff\n",
    "    filtered_df = df[df['ESM_vote'] >= k_cutoff]\n",
    "\n",
    "    # Filter based on dms_name not being NaN\n",
    "    filtered_df = filtered_df[filtered_df[dms_name].notna()]  # Use dms_name variable\n",
    "    \n",
    "    # Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(f'hie_temp/{dataset_name}.csv', index=False)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_above_k_cutoff = len(filtered_df)\n",
    "    above_cutoff_and_k_cutoff = len(filtered_df[filtered_df[dms_name] >= cutoff])  # Use dms_name variable\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f'{dataset_name}:')\n",
    "    print(f'Total values above k_cutoff: {total_above_k_cutoff}')\n",
    "    print(f'Values above k_cutoff and cutoff: {above_cutoff_and_k_cutoff}')\n",
    "    print('-' * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_aa_mutants_fasta(wt_sequence, output_file):\n",
    "    aa_alphabet = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "\n",
    "    records = []\n",
    "    \n",
    "    # Add the wild-type sequence as the first record\n",
    "    wt_record = SeqRecord(Seq(wt_sequence), id=\"WT\", description=\"Wild-type sequence\")\n",
    "    records.append(wt_record)\n",
    "    \n",
    "    for i, wt_aa in enumerate(wt_sequence):\n",
    "        for mutant_aa in aa_alphabet:\n",
    "            if mutant_aa != wt_aa:\n",
    "                mutant_sequence = wt_sequence[:i] + mutant_aa + wt_sequence[i+1:]\n",
    "                variant = f'{wt_aa}{i+1}{mutant_aa}'\n",
    "                record = SeqRecord(Seq(mutant_sequence), id=variant, description=\"\")\n",
    "                records.append(record)\n",
    "\n",
    "    with open(output_file, \"w\") as handle:\n",
    "        SeqIO.write(records, handle, \"fasta\")\n",
    "    \n",
    "    # Print the number of records\n",
    "    num_records = len(records)\n",
    "    print(f\"Number of records: {num_records}\")\n",
    "\n",
    "def generate_n_mutant_combinations_fasta(wt_sequence, output_file, mutants, n):\n",
    "    records = []\n",
    "\n",
    "    # Add the wild-type sequence as the first record\n",
    "    wt_record = SeqRecord(Seq(wt_sequence), id=\"WT\", description=\"Wild-type sequence\")\n",
    "    records.append(wt_record)\n",
    "\n",
    "    mutant_combinations = list(combinations(mutants['variant'], n))\n",
    "\n",
    "    for combination in mutant_combinations:\n",
    "        # rest of the code remains the same\n",
    "        positions = set()\n",
    "        valid_combination = True\n",
    "        mutant_sequence = wt_sequence\n",
    "        variant = \"\"\n",
    "\n",
    "        for mutant in combination:\n",
    "            wt_aa = mutant[0]\n",
    "            position = mutant[1:-1]  # Extract position from the middle of the string\n",
    "            mutant_aa = mutant[-1]            \n",
    "            \n",
    "            i = int(position) - 1  # Convert position to 0-based index\n",
    "            if i in positions:\n",
    "                # Position is already used in this combination\n",
    "                print(f\"Invalid combination: {combination}\")\n",
    "                valid_combination = False\n",
    "                break\n",
    "\n",
    "            positions.add(i)\n",
    "            mutant_sequence = mutant_sequence[:i] + mutant_aa + mutant_sequence[i + 1:]\n",
    "            variant += f'{wt_aa}{position}{mutant_aa}_'\n",
    "\n",
    "        if valid_combination:\n",
    "            # print the combination\n",
    "            print(f\"Combination: {combination}\")\n",
    "            record = SeqRecord(Seq(mutant_sequence), id=variant.rstrip('_'), description=\"\")\n",
    "            records.append(record)\n",
    "\n",
    "    # print number of records\n",
    "    print(f\"Number of combinations: {len(mutant_combinations)}\")\n",
    "    print(f\"Number of records: {len(records)}\")\n",
    "    with open(output_file, \"w\") as handle:\n",
    "        SeqIO.write(records, handle, \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"MNTINIAKNDFSDIELAAIPFNTLADHYGERLAREQLALEHESYEMGEARFRKMFERQLKAGEVADNAAAKPLITTLLPKMIARINDWFEEVKAKRGKRPTAFQFLQEIKPEAVAYITIKTTLACLTSADNTTVQAVASAIGRAIEDEARFGRIRDLEAKHFKKNVEEQLNKRVGHVYKKAFMQVVEADMLSKGLLGGEAWSSWHKEDSIHVGVRCIEMLIESTGMVSLHRQNAGVVGQDSETIELAPEYAEAIATRAGALAGISPMFQPCVVPPKPWTGITGGGYWANGRRPLALVRTHSKKALMRYEDVYMPEVYKAINIAQNTAWKINKKVLAVANVITKWKHCPVEDIPAIEREELPMKPEDIDMNPEALTAWKRAAAAVYRKDKARKSRRISLEFMLEQANKFANHKAIWFPYNMDWRGRVYAVSMFNPQGNDMTKGLLTLAKGKPIGKEGYYWLKIHGANCAGVDKVPFPERIKFIEENHENIMACAKSPLENTWWAEQDSPFCFLAFCFEYAGVQHHGLSYNCSLPLAFDGSCSGIQHFSAMLRDEVGGRAVNLLPSETVQDIYGIVAKKVNEILQADAINGTDNEVVTVTDENTGEISEKVKLGTKALAGQWLAYGVTRSVTKRSVMTLAYGSKEFGFRQQVLEDTIQPAIDSGKGLMFTQPNQAAGYMAKLIWESVSVTVVAAVEAMNWLKSAAKLLAAEVKDKKTGEILRKRCAVHWVTPDGFPVWQEYKKPIQTRLNLMFLGQFRLQPTINTNKDSEIDAHKQESGIAPNFVHSQDGSHLRKTVVWAHEKYGIESFALIHDSFGTIPADAANLFKAVRETMVDTYESCDVLADFYDQFADQLHESQLDKMPALPAKGNLNLRDILESDFAFA\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/t7_pol.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_sequence = \"MNTINIAKNDFSDIELAAIPFNTLADHYGERLAREQLALEHESYEMGEARFRKMFERQLKAGEVADNAAAKPLITTLLPKMIARINDWFEEVKAKRGKRPTAFQFLQEIKPEAVAYITIKTTLACLTSADNTTVQAVASAIGRAIEDEARFGRIRDLEAKHFKKNVEEQLNKRVGHVYKKAFMQVVEADMLSKGLLGGEAWSSWHKEDSIHVGVRCIEMLIESTGMVSLHRQNAGVVGQDSETIELAPEYAEAIATRAGALAGISPMFQPCVVPPKPWTGITGGGYWANGRRPLALVRTHSKKALMRYEDVYMPEVYKAINIAQNTAWKINKKVLAVANVITKWKHCPVEDIPAIEREELPMKPEDIDMNPEALTAWKRAAAAVYRKDKARKSRRISLEFMLEQANKFANHKAIWFPYNMDWRGRVYAVSMFNPQGNDMTKGLLTLAKGKPIGKEGYYWLKIHGANCAGVDKVPFPERIKFIEENHENIMACAKSPLENTWWAEQDSPFCFLAFCFEYAGVQHHGLSYNCSLPLAFDGSCSGIQHFSAMLRDEVGGRAVNLLPSETVQDIYGIVAKKVNEILQADAINGTDNEVVTVTDENTGEISEKVKLGTKALAGQWLAYGVTRSVTKRSVMTLAYGSKEFGFRQQVLEDTIQPAIDSGKGLMFTQPNQAAGYMAKLIWESVSVTVVAAVEAMNWLKSAAKLLAAEVKDKKTGEILRKRCAVHWVTPDGFPVWQEYKKPIQTRLNLMFLGQFRLQPTINTNKDSEIDAHKQESGIAPNFVHSQDGSHLRKTVVWAHEKYGIESFALIHDSFGTIPADAANLFKAVRETMVDTYESCDVLADFYDQFADQLHESQLDKMPALPAKGNLNLRDILESDFAFA\"\n",
    "\n",
    "t7_n_mutant = pd.read_excel('n_mutant_dicts/t7_n_mutants.xlsx', header=None)\n",
    "t7_n_mutant = t7_n_mutant[t7_n_mutant[1] > 1]\n",
    "t7_n_mutant[['position', 'mutant_aa']] = t7_n_mutant[0].str.extract('(\\d+)([A-Z]+)', expand=True)\n",
    "t7_n_mutant = t7_n_mutant[t7_n_mutant['position'] != '884']\n",
    "t7_n_mutant['wt_aa'] = t7_n_mutant.apply(lambda row: wt_sequence[int(row['position'])-1], axis=1)\n",
    "t7_n_mutant['variant'] = t7_n_mutant['wt_aa'] + t7_n_mutant['position'] + t7_n_mutant['mutant_aa']\n",
    "t7_n_mutant = t7_n_mutant[['variant']]\n",
    "\n",
    "# print number of rows\n",
    "print(f\"Number of rows: {len(t7_n_mutant)}\")\n",
    "t7_n_mutant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_2nd.fasta\", t7_n_mutant, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_3rd.fasta\", t7_n_mutant, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_4th.fasta\", t7_n_mutant, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_5th.fasta\", t7_n_mutant, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_6th.fasta\", t7_n_mutant, n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_n_mutant_combinations_fasta(wt_sequence, \"wet_lab/t7_pol_7th.fasta\", t7_n_mutant, n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"VKVTVPDKNPPCPCCSTRLNSVLALIDHLKGSHGKRRVCFRCAKCGRENFNHHSTVCHFAKCKGPSEEKPPVGEWICEVCGRDFTTKIGLGQHKRLAHPMVRNQERIDASQPKETSNRGAHKKCWTKEEEELLARLEVQFEGHKNINKLIAEHITTKTNKQISDKRRQMTRKDKGEGGAAGKLGPDTGRGNHSQAKVGNNGLGGNQLPGGPAATKDKAGCHLDKEEGNRIAISQQKKGRLQGRYHKEIKRRLEEGVINTFTKAFKQLLECQEVQPLINKTAQDCFGLLESACHIRTALRGKNKKETQEKPTGGQCLKWMKKRAVKKGNYLRFQRLFHLDRGKLARIILDDIECLSCDIAPSEIYSVFKARWETPGQFAGLGNFKSTGKADNKAFSDLITAKEIKKNVQEMSKGSAPGPDGIAIGDIKGMDPGYSRTAELFNLWLTSGEIPDMVRGCRTVLIPKSTQPERLKDINNWRPITIGSILLRLFSRIITARMTKACPLNPRQRGFIRAAGCSENLKLLQTIIRTAKSEHRPLGVVFVDIAKAFDTVSHQHILHVLQQRGVDPHIIGLVSNMYKDISTFVTTKKDTHTDKIQIRVGVKQGDPLSPLLFNLAMDPLLCKLEESGNGFHRGGHTITAMAFADDLVLLSDSWENMEKNIEILEAFCDLTGLKTQGQKCHGFYIKPTKDSYTVNNCAAWTIYGTPLNMINPGDSEKYLGLQIDPWTGIARSNISSKLDSWLERINQAPLKPLQKLDILKTYTIPRLTYMVDHSEMKAGALEALDLQIRSAVKDWLHLPSCTCDAILYVSTKDGGLGVTKLAGLIPSIQARRLHRIAQSPDETMKAFLDKEQMEKQYAKLWVQAGGKREKIPSIWDALPTPVLLTTSDTLSEWEAPNPKSKYPRPCNWRRKEFEKWTKLQCQGRGIQNFKGDVISNNWIQNYRRIPHRKLLTAVQLRANVYPTREFLGRGRGDDCVKFCRHCEVDLETCGHIISYCPVTKEARIKRHNRICERLIEEAEKKDWVVFKEPHIRDAVKELFKPDLIFVKEDRALVVDVTVRFEATTTSLEEAAIEKVDKYKRLETEVRSLTNAKDVLFMGFPLGARGKWYQGNFKLLDMLGLSESRQVTVAKTLSTDALISSVDIVHMFASKARKMNLVTV\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/r2.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"MKRKREDLTLWDAANVHKHKSMWYWWEYIRRKDMVNHEKTDCDVIQLLQSASVKKQKTQSDKFLTSFSVGIRPTKHQKRVLNEMLRVSNYTYNWCLWLVNEKGLKPHQFELQKIVCKTNANDVDPQYRMENDDWFFNNKMTSVKLTSCKNFCTSYKSAKSLKSKLKRPMSVSNIIQGSFCVPKLFIRHLSSKDVSTDNTNMQNRYICMMPDNFEKRSNPKERFLKLAKPITKIPPIDHDVKIVKRADGMFIMNIPCDPKYTRRNASNDTIEKRVCGIDPGGRTFATVYDPIDCCVFQVGIKEDKQYVISKLHNKIDHAHMHLTKAQNKKQQQAARERIVSLKKTHLKLKTFVDDIHLKLSSHLVKEYQYVALGKINVAQLVKTDRPKPLSKRAKRDLLYWQHYRFRQRLTHRTTNTECILDVQNEAYTSKTCGVCGTINKNLEKSETFYCDQCKYNTHRDVNGARNILLKSLRMFPFEKQQQ\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/fanzor.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"LNIEDEYRLHETSKEPDVSLGSTWLSDFPQAWAETGGMGLAVRQAPLIIPLKATSTPVSIKQYPMSQEARLGIKPHIQRLLDQGILVPCQSPWNTPLLPVKKPGTNDYRPVQDLREVNKRVEDIHPTVPNPYNLLSGLPPSHQWYTVLDLKDAFFCLRLHPTSQPLFAFEWRDPEMGISGQLTWTRLPQGFKNSPTLFNEALHRDLADFRIQHPDLILLQYVDDLLLAATSELDCQQGTRALLQTLGNLGYRASAKKAQICQKQVKYLGYLLKEGQRWLTEARKETVMGQPTPKTPRQLREFLGKAGFCRLFIPGFAEMAAPLYPLTKPGTLFNWGPDQQKAYQEIKQALLTAPALGLPDLTKPFELFVDEKQGYAKGVLTQKLGPWRRPVAYLSKKLDPVAAGWPPCLRMVAAIAVLTKDAGKLTMGQPLVILAPHAVEALVKQPPDRWLSNARMTHYQALLLDTDRVQFGPVVALNPATLLPLPEEGLQHNCLDILAEAHGTRPDLTDQPLPDADHTWYTDGSSLLQEGQRKAGAAVTTETEVIWAKALPAGTSAQRAELIALTQALKMAEGKKLNVYTDSRYAFATAHIHGEIYRRRGWLTSEGKEIKNKDEILALLKALFLPKRLSIIHCPGHQKGHSAEARGNRMADQAARKAAITETPDTSTLLIENSSP\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/mlv.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"MRALVVIRLSRVTDATTSPERQLESCQQLCAQRGWDVVGVAEDLDVSGAVDPFDRKRRPNLARWLAFEEQPFDVIVAYRVDRLTRSIRHLQQLVHWAEDHKKLVVSATEAHFDTTTPFAAVVIALMGTVAQMELEAIKERNRSAAHFNIRAGKYRGSLPPWGYLPTRVDGEWRLVPDPVQRERILEVYHRVVDNHEPLHLVAHDLNRRGVLSPKDYFAQLQGREPQGREWSATALKRSMISEAMLGYATLNGKTVRDDDGAPLVRAEPILTREQLEALRAELVKTSRAKPAVSTPSLLLRVLFCAVCGEPAYKFAGGGRKHPRYRCRSMGFPKHCGNGTVAMAEWDAFCEEQVLDLLGDAERLEKVWVAGSDSAVELAEVNAELVDLTSLIGSPAYRAGSPQREALDARIAALAARQEELEGLEARPSGWEWRETGQRFGDWWREQDTAAKNTWLRSMNVRLTFDVRGGLTRTIDFGDLQEYEQHLRLGSVVERLHTGMS\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/bxb1.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"MTVTDDYLANNVDYASGFKGPLPMPPSKHIAIVACMDARLDVYRMLGIKEGEAHVIRNAGCVVTDDVIRSLAISQRLLGTREIILLHHTDCGMLTFTDDDFKRAIQDETGIRPTWSPESYPDAVEDVRQSLRRIEVNPFVTKHTSLRGFVFDVATGKLNEVTPAAALEARKEAELAAATAEQ\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/ca.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "wt_sequence = \"MKRKREQMTLWKAAFVNGQETFKSWIDKARMLELNCDVSSASSTHYSDLNLKTKCAKMEDKFMCTFSVGIRPTSKQKRTLNQMLKVSNHAYNWCNYLVKEKDFKPKQFDLQRVVTKTNSTDVPAEYRLPGDDWFFDNKMSSIKLTACKNFCTMYKSAQTNQKKTKVDLRNKDIAMLREGSFEVQKKYVRLLTEKDIPDERIRQSRIALMADNFSKSKKDWKERFLRLSKNVSKIPPLSHDMKVCKRPNGKFVLQIPCDPIYTRQIQVHTSDSICSIDPGGRTFATCYDPSNIKAFQIGPEADKKEVIHKYHEKIDYVHRLLAYAQKKKQTQAVQDRIGQLKKLHLKLKTYVDDVHLKLCSYLVKNYKLVVLGKISVSSIVRKDRPNHLAKKANRDLLCWQHYRFRQRLLHRVRGTDCEAIAQDERYTSKTCGNCGVKNNKLGGKETFICESCNYKTHRDVNGARNILCKYLGLFPFAA\"\n",
    "print(len(wt_sequence))\n",
    "output_file = \"wet_lab/mmfunc.fasta\"\n",
    "generate_single_aa_mutants_fasta(wt_sequence, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
