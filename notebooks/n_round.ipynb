{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import xgboost\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Ignore FutureWarnings and ConvergenceWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn.neural_network\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions ported from grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read in the data\n",
    "def read_data(dataset_name, base_path, file_type, embeddings_type='both', experimental = False):\n",
    "    # Construct the file paths\n",
    "    if file_type == \"csvs\":\n",
    "        labels_file = os.path.join(base_path, 'labels', dataset_name.split('_')[0] + '_labels.csv')\n",
    "        hie_file = os.path.join(base_path, 'hie_temp', dataset_name.split('_')[0] + '.csv')\n",
    "        embeddings_file = os.path.join(base_path, 'csvs', dataset_name + '.csv')\n",
    "        # Read in mean embeddings across all rounds\n",
    "        embeddings = pd.read_csv(embeddings_file, index_col=0)\n",
    "    elif file_type == \"pts\":\n",
    "        labels_file = os.path.join(base_path, 'labels', dataset_name.split('_')[-1] + '_labels.csv')\n",
    "        hie_file = os.path.join(base_path, 'hie_temp', dataset_name.split('_')[-1] + '.csv')\n",
    "        embeddings_file = os.path.join(base_path, 'pts', dataset_name + '.pt')\n",
    "        # Read in pytorch tensor of embeddings\n",
    "        embeddings = torch.load(embeddings_file)\n",
    "        # Convert embeddings to a dataframe\n",
    "        if embeddings_type == 'average':\n",
    "            embeddings = {key: value['average'].numpy() for key, value in embeddings.items()}\n",
    "        elif embeddings_type == 'mutated':\n",
    "            embeddings = {key: value['mutated'].numpy() for key, value in embeddings.items()}\n",
    "        elif embeddings_type == 'both':\n",
    "            embeddings = {key: torch.cat((value['average'], value['mutated'])).numpy() for key, value in embeddings.items()}\n",
    "        else:\n",
    "            print(\"Invalid embeddings_type. Please choose 'average', 'mutated', or 'both'\")\n",
    "            return None, None\n",
    "\n",
    "        # Convert embeddings dictionary to a dataframe\n",
    "        embeddings = pd.DataFrame.from_dict(embeddings, orient='index')\n",
    "    else:\n",
    "        print(\"Invalid file type. Please choose either 'csvs' or 'pts'\")\n",
    "        return None, None\n",
    "\n",
    "    # if not experimental\n",
    "    if not experimental:\n",
    "        # Read in labels\n",
    "        labels = pd.read_csv(labels_file)\n",
    "\n",
    "        # Read in hierarchy\n",
    "        hie_data = pd.read_csv(hie_file)\n",
    "\n",
    "        # Filter out rows where fitness is NaN\n",
    "        labels = labels[labels['fitness'].notna()]\n",
    "\n",
    "        # Filter out rows in embeddings where row names are not in labels variant column\n",
    "        embeddings = embeddings[embeddings.index.isin(labels['variant'])]\n",
    "\n",
    "        # Align labels by variant\n",
    "        labels = labels.sort_values(by=['variant'])\n",
    "\n",
    "        # Align embeddings by row name\n",
    "        embeddings = embeddings.sort_index()\n",
    "\n",
    "        # Confirm that labels and embeddings are aligned, reset index\n",
    "        labels = labels.reset_index(drop=True)\n",
    "\n",
    "        # Get the variants in labels and embeddings, convert to list\n",
    "        label_variants = labels['variant'].tolist()\n",
    "        embedding_variants = embeddings.index.tolist()\n",
    "\n",
    "        # Check if embedding row names and label variants are identical\n",
    "        if label_variants == embedding_variants:\n",
    "            print('Embeddings and labels are aligned')\n",
    "\n",
    "        # return embeddings and labels\n",
    "        return embeddings, labels, hie_data\n",
    "\n",
    "    else:\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Active learning function for one iteration\n",
    "def top_layer(iter_train, iter_test, embeddings_pd, labels_pd, measured_var, regression_type='ridge', top_n=None, final_round=10):\n",
    "    # reset the indices of embeddings_pd and labels_pd\n",
    "    embeddings_pd = embeddings_pd.reset_index(drop=True)\n",
    "    labels_pd = labels_pd.reset_index(drop=True)\n",
    "\n",
    "    # save column 'iteration' in the labels dataframe\n",
    "    iteration = labels_pd['iteration']\n",
    "\n",
    "    # save labels\n",
    "    labels = labels_pd\n",
    "\n",
    "    # save mean embeddings as numpy array\n",
    "    a = embeddings_pd\n",
    "\n",
    "    # subset a, y to only include the rows where iteration = iter_train and iter_test\n",
    "    idx_train = iteration[iteration.isin(iter_train)].index.to_numpy()\n",
    "    idx_test = iteration[iteration.isin([iter_test])].index.to_numpy()\n",
    "\n",
    "    # subset a to only include the rows where iteration = iter_train and iter_test\n",
    "    X_train = a.loc[idx_train, :]\n",
    "    X_test = a.loc[idx_test, :]\n",
    "\n",
    "    y_train = labels[iteration.isin(iter_train)][measured_var]\n",
    "\n",
    "    y_test = labels[iteration.isin([iter_test])][measured_var]\n",
    "\n",
    "    # fit\n",
    "    if regression_type == 'ridge':\n",
    "        model = linear_model.RidgeCV()\n",
    "    elif regression_type == 'lasso':\n",
    "        model = linear_model.LassoCV(max_iter=100000,tol=1e-3)\n",
    "    elif regression_type == 'elasticnet':\n",
    "        model = linear_model.ElasticNetCV(max_iter=100000,tol=1e-3)\n",
    "    elif regression_type == 'linear':\n",
    "        model = linear_model.LinearRegression()\n",
    "    elif regression_type == 'neuralnet':\n",
    "        model = MLPRegressor(hidden_layer_sizes=(5), max_iter=1000, activation='relu', solver='adam', alpha=0.001,\n",
    "                             batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5,\n",
    "                             momentum=0.9, nesterovs_momentum=True, shuffle=True, random_state=1, tol=0.0001,\n",
    "                             verbose=False, warm_start=False, early_stopping=False, validation_fraction=0.1, beta_1=0.9,\n",
    "                             beta_2=0.999, epsilon=1e-08)\n",
    "    elif regression_type == 'randomforest':\n",
    "        model = RandomForestRegressor(n_estimators=100, criterion='friedman_mse', max_depth=None, min_samples_split=2,\n",
    "                                      min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                                      max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False,\n",
    "                                      n_jobs=None, random_state=1, verbose=0, warm_start=False, ccp_alpha=0.0,\n",
    "                                      max_samples=None)\n",
    "    elif regression_type == 'gradientboosting':\n",
    "        model = xgboost.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                                     max_depth=5, alpha=10, n_estimators=10)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions on train data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_std_train = np.zeros(len(y_pred_train))\n",
    "    # make predictions on test data\n",
    "    # NOTE: can work on alternate 2-n round strategies here\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_std_test = np.zeros(len(y_pred_test))\n",
    "\n",
    "    # combine predicted and actual thermostability values with sequence IDs into a new dataframe\n",
    "    df_train = pd.DataFrame({'variant': labels.variant[idx_train], 'y_pred': y_pred_train, 'y_actual': y_train})\n",
    "    df_test = pd.DataFrame({'variant': labels.variant[idx_test], 'y_pred': y_pred_test, 'y_actual': y_test})\n",
    "    \n",
    "    # sort df_test by y_pred\n",
    "    df_test = df_test.sort_values(by=['y_pred'], ascending=False)\n",
    "\n",
    "    df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "    # sort df_all by y_pred\n",
    "    df_all = df_all.sort_values(by=['y_pred'], ascending=False)\n",
    "\n",
    "    return df_test, df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_experimental_data(base_path, round_file_name, t7_sequence):\n",
    "    file_path = base_path + '/rounds/' + round_file_name\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Clean up 'Variant' column\n",
    "    df['Variant'] = df['Variant'].str.replace('T7pol_', '')\n",
    "\n",
    "    # Iterate through the 'Variant' column and update the values based on t7_sequence\n",
    "    updated_variants = []\n",
    "    for _, row in df.iterrows():\n",
    "        variant = row['Variant']\n",
    "        if variant == 'WT':\n",
    "            updated_variants.append(variant)\n",
    "        else:\n",
    "            position = int(variant[:-1])\n",
    "            wt_aa = t7_sequence[position - 1]\n",
    "            updated_variant = wt_aa + variant\n",
    "            updated_variants.append(updated_variant)\n",
    "    \n",
    "    df['updated_variant'] = updated_variants  # Add the updated variants to the DataFrame\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_dataframes(df, expected_index):\n",
    "    # First dataframe\n",
    "    df1 = df.copy()\n",
    "    df1.loc[df1['updated_variant'] == 'WT', 'iteration'] = 0\n",
    "    df1.loc[df1['updated_variant'] != 'WT', 'iteration'] = 1\n",
    "    df1['iteration'] = df1['iteration'].astype(int)\n",
    "    df1.rename(columns={'updated_variant': 'variant'}, inplace=True)  # Rename the column\n",
    "    df1 = df1[['variant', 'iteration']]\n",
    "    \n",
    "    # Second dataframe\n",
    "    df2 = df.copy()\n",
    "    df2.rename(columns={'Effect vector': 'fitness'}, inplace=True)  # Rename the column\n",
    "    df2.loc[df2['updated_variant'] == 'WT', 'iteration'] = 0\n",
    "    df2.loc[df2['updated_variant'] != 'WT', 'iteration'] = 1\n",
    "    df2.rename(columns={'updated_variant': 'variant'}, inplace=True)  # Rename the column\n",
    "    df2['iteration'] = df2['iteration'].astype(int)\n",
    "    df2 = df2[['variant', 'fitness', 'iteration']]\n",
    "\n",
    "    expected_index = [variant for variant in expected_index if variant not in df2['variant'].tolist()]\n",
    "    # make a df_external that has a column 'variant' with all the variants in expected_index\n",
    "    df_external = pd.DataFrame({'variant': expected_index})\n",
    "    df_external = pd.DataFrame({'variant': expected_index})\n",
    "    df_external['fitness'] = np.nan  \n",
    "    df_external['iteration'] = 1001 \n",
    "    df2 = df2.append(df_external, ignore_index=True)\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import brenan data\n",
    "dataset_name = 'esm2_15B_t7_pol'\n",
    "base_path = '/Users/matteodibernardo/Documents/GitHub/directed_evolution/notebooks/t7/'\n",
    "file_type = 'pts'\n",
    "embeddings_type = 'average'\n",
    "experimental = True\n",
    "embeddings = read_data(dataset_name, base_path, file_type, embeddings_type, experimental)\n",
    "# replace WT Wild-type sequence index in embeddings with 'WT'\n",
    "embeddings.index.values[0] = 'WT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5110</th>\n",
       "      <th>5111</th>\n",
       "      <th>5112</th>\n",
       "      <th>5113</th>\n",
       "      <th>5114</th>\n",
       "      <th>5115</th>\n",
       "      <th>5116</th>\n",
       "      <th>5117</th>\n",
       "      <th>5118</th>\n",
       "      <th>5119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WT</th>\n",
       "      <td>0.147168</td>\n",
       "      <td>-0.183875</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>-0.052828</td>\n",
       "      <td>-0.141786</td>\n",
       "      <td>-0.013741</td>\n",
       "      <td>-0.061830</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110809</td>\n",
       "      <td>0.051659</td>\n",
       "      <td>0.059534</td>\n",
       "      <td>-0.157181</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.020313</td>\n",
       "      <td>0.015764</td>\n",
       "      <td>0.064493</td>\n",
       "      <td>-0.008039</td>\n",
       "      <td>-0.108970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1A</th>\n",
       "      <td>0.147994</td>\n",
       "      <td>-0.184054</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>-0.053447</td>\n",
       "      <td>-0.140782</td>\n",
       "      <td>-0.016417</td>\n",
       "      <td>-0.063300</td>\n",
       "      <td>-0.028770</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.022787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111060</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>0.060578</td>\n",
       "      <td>-0.156948</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.018843</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.063135</td>\n",
       "      <td>-0.005746</td>\n",
       "      <td>-0.106902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1C</th>\n",
       "      <td>0.149553</td>\n",
       "      <td>-0.182680</td>\n",
       "      <td>0.033869</td>\n",
       "      <td>-0.054389</td>\n",
       "      <td>-0.140723</td>\n",
       "      <td>-0.015113</td>\n",
       "      <td>-0.064822</td>\n",
       "      <td>-0.028185</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.027269</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111689</td>\n",
       "      <td>0.051024</td>\n",
       "      <td>0.059965</td>\n",
       "      <td>-0.157671</td>\n",
       "      <td>0.012664</td>\n",
       "      <td>0.019815</td>\n",
       "      <td>0.015817</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>-0.007434</td>\n",
       "      <td>-0.108856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1D</th>\n",
       "      <td>0.146734</td>\n",
       "      <td>-0.182717</td>\n",
       "      <td>0.034278</td>\n",
       "      <td>-0.052991</td>\n",
       "      <td>-0.140832</td>\n",
       "      <td>-0.015275</td>\n",
       "      <td>-0.063740</td>\n",
       "      <td>-0.028154</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.025465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111113</td>\n",
       "      <td>0.050927</td>\n",
       "      <td>0.060537</td>\n",
       "      <td>-0.156441</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>0.019746</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>0.063376</td>\n",
       "      <td>-0.006656</td>\n",
       "      <td>-0.107104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1E</th>\n",
       "      <td>0.149375</td>\n",
       "      <td>-0.184232</td>\n",
       "      <td>0.034520</td>\n",
       "      <td>-0.054731</td>\n",
       "      <td>-0.140585</td>\n",
       "      <td>-0.016518</td>\n",
       "      <td>-0.064851</td>\n",
       "      <td>-0.028408</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>0.025971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110941</td>\n",
       "      <td>0.051635</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>-0.157911</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.062794</td>\n",
       "      <td>-0.007955</td>\n",
       "      <td>-0.106604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A883S</th>\n",
       "      <td>0.145864</td>\n",
       "      <td>-0.184623</td>\n",
       "      <td>0.031468</td>\n",
       "      <td>-0.051257</td>\n",
       "      <td>-0.142275</td>\n",
       "      <td>-0.012640</td>\n",
       "      <td>-0.061425</td>\n",
       "      <td>-0.027589</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>0.025046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110233</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.058792</td>\n",
       "      <td>-0.157249</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>0.018916</td>\n",
       "      <td>0.019343</td>\n",
       "      <td>0.065511</td>\n",
       "      <td>-0.009308</td>\n",
       "      <td>-0.109120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A883T</th>\n",
       "      <td>0.145933</td>\n",
       "      <td>-0.184290</td>\n",
       "      <td>0.031539</td>\n",
       "      <td>-0.051148</td>\n",
       "      <td>-0.141504</td>\n",
       "      <td>-0.012715</td>\n",
       "      <td>-0.062040</td>\n",
       "      <td>-0.028451</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110211</td>\n",
       "      <td>0.052196</td>\n",
       "      <td>0.058730</td>\n",
       "      <td>-0.158339</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.065699</td>\n",
       "      <td>-0.010361</td>\n",
       "      <td>-0.109183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A883V</th>\n",
       "      <td>0.145253</td>\n",
       "      <td>-0.182491</td>\n",
       "      <td>0.031516</td>\n",
       "      <td>-0.052928</td>\n",
       "      <td>-0.142025</td>\n",
       "      <td>-0.013264</td>\n",
       "      <td>-0.060926</td>\n",
       "      <td>-0.027928</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111040</td>\n",
       "      <td>0.051419</td>\n",
       "      <td>0.060660</td>\n",
       "      <td>-0.157816</td>\n",
       "      <td>0.012737</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.065630</td>\n",
       "      <td>-0.008499</td>\n",
       "      <td>-0.109677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A883W</th>\n",
       "      <td>0.145614</td>\n",
       "      <td>-0.183985</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>-0.051818</td>\n",
       "      <td>-0.142407</td>\n",
       "      <td>-0.012759</td>\n",
       "      <td>-0.059910</td>\n",
       "      <td>-0.027657</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110127</td>\n",
       "      <td>0.052603</td>\n",
       "      <td>0.059757</td>\n",
       "      <td>-0.156924</td>\n",
       "      <td>0.013284</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>-0.009098</td>\n",
       "      <td>-0.108907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A883Y</th>\n",
       "      <td>0.145630</td>\n",
       "      <td>-0.183604</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>-0.052555</td>\n",
       "      <td>-0.142431</td>\n",
       "      <td>-0.013025</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>-0.027227</td>\n",
       "      <td>0.017617</td>\n",
       "      <td>0.024901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110390</td>\n",
       "      <td>0.052647</td>\n",
       "      <td>0.059469</td>\n",
       "      <td>-0.156905</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>0.018913</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.065339</td>\n",
       "      <td>-0.008382</td>\n",
       "      <td>-0.108806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16778 rows × 5120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "WT     0.147168 -0.183875  0.031651 -0.052828 -0.141786 -0.013741 -0.061830   \n",
       "M1A    0.147994 -0.184054  0.035075 -0.053447 -0.140782 -0.016417 -0.063300   \n",
       "M1C    0.149553 -0.182680  0.033869 -0.054389 -0.140723 -0.015113 -0.064822   \n",
       "M1D    0.146734 -0.182717  0.034278 -0.052991 -0.140832 -0.015275 -0.063740   \n",
       "M1E    0.149375 -0.184232  0.034520 -0.054731 -0.140585 -0.016518 -0.064851   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "A883S  0.145864 -0.184623  0.031468 -0.051257 -0.142275 -0.012640 -0.061425   \n",
       "A883T  0.145933 -0.184290  0.031539 -0.051148 -0.141504 -0.012715 -0.062040   \n",
       "A883V  0.145253 -0.182491  0.031516 -0.052928 -0.142025 -0.013264 -0.060926   \n",
       "A883W  0.145614 -0.183985  0.031491 -0.051818 -0.142407 -0.012759 -0.059910   \n",
       "A883Y  0.145630 -0.183604  0.031467 -0.052555 -0.142431 -0.013025 -0.060731   \n",
       "\n",
       "           7         8         9     ...      5110      5111      5112  \\\n",
       "WT    -0.028053  0.018626  0.025174  ... -0.110809  0.051659  0.059534   \n",
       "M1A   -0.028770  0.018573  0.022787  ... -0.111060  0.049681  0.060578   \n",
       "M1C   -0.028185  0.018523  0.027269  ... -0.111689  0.051024  0.059965   \n",
       "M1D   -0.028154  0.018495  0.025465  ... -0.111113  0.050927  0.060537   \n",
       "M1E   -0.028408  0.018998  0.025971  ... -0.110941  0.051635  0.058811   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "A883S -0.027589  0.017693  0.025046  ... -0.110233  0.051852  0.058792   \n",
       "A883T -0.028451  0.017504  0.024164  ... -0.110211  0.052196  0.058730   \n",
       "A883V -0.027928  0.017077  0.024314  ... -0.111040  0.051419  0.060660   \n",
       "A883W -0.027657  0.016999  0.023699  ... -0.110127  0.052603  0.059757   \n",
       "A883Y -0.027227  0.017617  0.024901  ... -0.110390  0.052647  0.059469   \n",
       "\n",
       "           5113      5114      5115      5116      5117      5118      5119  \n",
       "WT    -0.157181  0.013038  0.020313  0.015764  0.064493 -0.008039 -0.108970  \n",
       "M1A   -0.156948  0.011523  0.018843  0.014856  0.063135 -0.005746 -0.106902  \n",
       "M1C   -0.157671  0.012664  0.019815  0.015817  0.063816 -0.007434 -0.108856  \n",
       "M1D   -0.156441  0.011660  0.019746  0.013886  0.063376 -0.006656 -0.107104  \n",
       "M1E   -0.157911  0.012537  0.020981  0.014563  0.062794 -0.007955 -0.106604  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "A883S -0.157249  0.013417  0.018916  0.019343  0.065511 -0.009308 -0.109120  \n",
       "A883T -0.158339  0.012717  0.018639  0.020539  0.065699 -0.010361 -0.109183  \n",
       "A883V -0.157816  0.012737  0.018943  0.017333  0.065630 -0.008499 -0.109677  \n",
       "A883W -0.156924  0.013284  0.018394  0.016497  0.064918 -0.009098 -0.108907  \n",
       "A883Y -0.156905  0.012707  0.018913  0.016970  0.065339 -0.008382 -0.108806  \n",
       "\n",
       "[16778 rows x 5120 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variant  Effect vector updated_variant\n",
      "0     12N       1.073846            S12N\n",
      "1     25N       0.677227            A25N\n",
      "2      WT       1.000000              WT\n",
      "3     89R       0.740499            F89R\n",
      "4    134T       1.074891           V134T\n",
      "5    177L       1.042706           V177L\n",
      "6    225E       1.075861           G225E\n",
      "7    241W       0.938351           S241W\n",
      "8    273H       0.785147           V273H\n"
     ]
    }
   ],
   "source": [
    "base_path = '/Users/matteodibernardo/Documents/GitHub/directed_evolution/notebooks/t7/'\n",
    "round_file_name = 'T7_Round1.xlsx'\n",
    "t7_sequence = 'MNTINIAKNDFSDIELAAIPFNTLADHYGERLAREQLALEHESYEMGEARFRKMFERQLKAGEVADNAAAKPLITTLLPKMIARINDWFEEVKAKRGKRPTAFQFLQEIKPEAVAYITIKTTLACLTSADNTTVQAVASAIGRAIEDEARFGRIRDLEAKHFKKNVEEQLNKRVGHVYKKAFMQVVEADMLSKGLLGGEAWSSWHKEDSIHVGVRCIEMLIESTGMVSLHRQNAGVVGQDSETIELAPEYAEAIATRAGALAGISPMFQPCVVPPKPWTGITGGGYWANGRRPLALVRTHSKKALMRYEDVYMPEVYKAINIAQNTAWKINKKVLAVANVITKWKHCPVEDIPAIEREELPMKPEDIDMNPEALTAWKRAAAAVYRKDKARKSRRISLEFMLEQANKFANHKAIWFPYNMDWRGRVYAVSMFNPQGNDMTKGLLTLAKGKPIGKEGYYWLKIHGANCAGVDKVPFPERIKFIEENHENIMACAKSPLENTWWAEQDSPFCFLAFCFEYAGVQHHGLSYNCSLPLAFDGSCSGIQHFSAMLRDEVGGRAVNLLPSETVQDIYGIVAKKVNEILQADAINGTDNEVVTVTDENTGEISEKVKLGTKALAGQWLAYGVTRSVTKRSVMTLAYGSKEFGFRQQVLEDTIQPAIDSGKGLMFTQPNQAAGYMAKLIWESVSVTVVAAVEAMNWLKSAAKLLAAEVKDKKTGEILRKRCAVHWVTPDGFPVWQEYKKPIQTRLNLMFLGQFRLQPTINTNKDSEIDAHKQESGIAPNFVHSQDGSHLRKTVVWAHEKYGIESFALIHDSFGTIPADAANLFKAVRETMVDTYESCDVLADFYDQFADQLHESQLDKMPALPAKGNLNLRDILESDFAFA'\n",
    "experimental_data = read_experimental_data(base_path, round_file_name, t7_sequence)\n",
    "print(experimental_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_one, labels_one = create_dataframes(experimental_data, embeddings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_old = iterations_one\n",
    "embeddings_pd = embeddings\n",
    "labels_pd = labels_one\n",
    "measured_var = 'fitness'\n",
    "regression_type = 'randomforest'\n",
    "num_mutants_per_round = 16\n",
    "final_round = 16\n",
    "\n",
    "df_test, df_all = top_layer(\n",
    "    iter_train=iteration_old['iteration'].unique().tolist(),\n",
    "    iter_test=1001,\n",
    "    embeddings_pd=embeddings_pd,\n",
    "    labels_pd=labels_pd,\n",
    "    measured_var=measured_var,\n",
    "    regression_type=regression_type,\n",
    "    top_n=None,\n",
    "    final_round=final_round\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>E249C</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>L294C</td>\n",
       "      <td>1.010837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>G469Q</td>\n",
       "      <td>1.010637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>T279S</td>\n",
       "      <td>1.009233</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>I281L</td>\n",
       "      <td>1.008760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M1I</td>\n",
       "      <td>0.907080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15452</th>\n",
       "      <td>F814G</td>\n",
       "      <td>0.906483</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M1C</td>\n",
       "      <td>0.906116</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M1E</td>\n",
       "      <td>0.905141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>F546G</td>\n",
       "      <td>0.901978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variant    y_pred  y_actual\n",
       "4715    E249C  1.011400       NaN\n",
       "5569    L294C  1.010837       NaN\n",
       "8905    G469Q  1.010637       NaN\n",
       "5298    T279S  1.009233       NaN\n",
       "5329    I281L  1.008760       NaN\n",
       "...       ...       ...       ...\n",
       "16        M1I  0.907080       NaN\n",
       "15452   F814G  0.906483       NaN\n",
       "10        M1C  0.906116       NaN\n",
       "12        M1E  0.905141       NaN\n",
       "10360   F546G  0.901978       NaN\n",
       "\n",
       "[16769 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a csv file\n",
    "df_test.to_csv('t7/round1_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S12N</td>\n",
       "      <td>1.022667</td>\n",
       "      <td>1.073846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V134T</td>\n",
       "      <td>1.011421</td>\n",
       "      <td>1.074891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4715</th>\n",
       "      <td>E249C</td>\n",
       "      <td>1.011400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>L294C</td>\n",
       "      <td>1.010837</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8905</th>\n",
       "      <td>G469Q</td>\n",
       "      <td>1.010637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M1E</td>\n",
       "      <td>0.905141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>F546G</td>\n",
       "      <td>0.901978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V273H</td>\n",
       "      <td>0.835153</td>\n",
       "      <td>0.785147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F89R</td>\n",
       "      <td>0.799308</td>\n",
       "      <td>0.740499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A25N</td>\n",
       "      <td>0.797952</td>\n",
       "      <td>0.677227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16778 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variant    y_pred  y_actual\n",
       "0        S12N  1.022667  1.073846\n",
       "4       V134T  1.011421  1.074891\n",
       "4715    E249C  1.011400       NaN\n",
       "5569    L294C  1.010837       NaN\n",
       "8905    G469Q  1.010637       NaN\n",
       "...       ...       ...       ...\n",
       "12        M1E  0.905141       NaN\n",
       "10360   F546G  0.901978       NaN\n",
       "8       V273H  0.835153  0.785147\n",
       "3        F89R  0.799308  0.740499\n",
       "1        A25N  0.797952  0.677227\n",
       "\n",
       "[16778 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
